{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jLDisQ6gAaMQ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "pwyZu2ibAhO1",
    "outputId": "01503b88-86a2-4619-d029-6ba8a7632cd8"
   },
   "outputs": [],
   "source": [
    "def loadIrisData():\n",
    "    iris = load_iris()\n",
    "    X=iris['data']\n",
    "    t=iris['target']\n",
    "    print(X.shape)\n",
    "    print(t.shape)\n",
    "    return X, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "48_5__HzBks_"
   },
   "outputs": [],
   "source": [
    "def one_hot_encoding(t_indices, N):\n",
    "    '''\n",
    "    Inputs:\n",
    "        t_indices: list of indices\n",
    "        N: total no. of classes\n",
    "    '''\n",
    "    assert N>max(t_indices), (N, max(t_indices))\n",
    "\n",
    "    ### WRITE YOUR CODE HERE - 2 MARKS\n",
    "    t_1hot = np.zeros((len(t_indices),N))\n",
    "    for i in range(len(t_indices)):\n",
    "        t_1hot[i][t_indices[i]] = 1.0\n",
    "    return t_1hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m2DsnXa89lIk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed üëç\n"
     ]
    }
   ],
   "source": [
    "def test_one_hot_encoding():\n",
    "    t_1hot = one_hot_encoding([0,2], 3)\n",
    "    t_1hotTrue = np.array([[1.,0.,0.], [0.,0.,1.]])\n",
    "    assert np.all(np.isclose( t_1hot, t_1hotTrue ))\n",
    "    print('Test passed', '\\U0001F44D')\n",
    "if __name__==\"__main__\":\n",
    "    test_one_hot_encoding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VXxxA2YkB_I8"
   },
   "outputs": [],
   "source": [
    "def splitData(X,t,testFraction=0.2):\n",
    "    \"\"\"\n",
    "    Use numpy functions only\n",
    "    Inputs:\n",
    "        X: np array of shape (Nsamples, dim)\n",
    "        t: np array of len Nsamples; can be one hot vectors or labels\n",
    "        testFraction: (float) Nsamples_test = testFraction * Nsamples\n",
    "    \"\"\"\n",
    "\n",
    "    ### WRITE YOUR CODE HERE - 2 MARKS\n",
    "    Nsamples_test = int(testFraction*X.shape[0])\n",
    "    indices = np.random.permutation(X.shape[0])\n",
    "    test_idx, training_idx = indices[:Nsamples_test], indices[Nsamples_test:]\n",
    "    X_train, t_train,X_test,t_test = X[training_idx],t[training_idx],X[test_idx],t[test_idx]\n",
    "    \n",
    "    return X_train, t_train, X_test, t_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed üëç\n"
     ]
    }
   ],
   "source": [
    "def test_splitData():\n",
    "    X = np.random.random((5,2))\n",
    "    t1hot = one_hot_encoding([1,0,2,1,2],3)\n",
    "    X_train, t1hot_train, X_test, t1hot_test = splitData(X,t1hot,.2)\n",
    "    assert X_train.shape==(4,2), [\"X_train.shape\", X_train.shape]\n",
    "    assert X_test.shape==(1,2), [\"X_test.shape\", X_test.shape]\n",
    "    print('Test passed', '\\U0001F44D')    \n",
    "if __name__==\"__main__\":\n",
    "    test_splitData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OK2lZ6ZpCjAg"
   },
   "outputs": [],
   "source": [
    "### Normalize data to be of zero mean and unit variance\n",
    "def normalizeX(X_train, X_test):\n",
    "    '''\n",
    "    Inputs:\n",
    "        X_train: np array 2d\n",
    "        X_test: np array 2d\n",
    "    Outputs:\n",
    "        Normalized np arrays 2d\n",
    "    '''\n",
    "\n",
    "    ### WRITE YOUR CODE HERE - 2 MARKS\n",
    "    mean = np.mean(X_train,axis=0)\n",
    "    std  = np.std(X_train,axis=0)\n",
    "    X_train_normalized = (X_train-mean)/std\n",
    "    X_test_normalized = (X_test-mean)/std\n",
    "    \n",
    "    return X_train_normalized, X_test_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed üëç\n"
     ]
    }
   ],
   "source": [
    "def test_normalizeX():\n",
    "    X_train = np.array([[1,1,0],[2,2,1]])\n",
    "    X_test = np.array([[1,1,0],[3,3,2]])\n",
    "    X_train_normalized, X_test_normalized = normalizeX(X_train, X_test)\n",
    "    a = np.array([[-1.,-1.,-1.], [ 1., 1., 1.]])\n",
    "    b = np.array([[-1.,-1.,-1.], [ 3., 3., 3.]])\n",
    "    assert np.all(np.isclose( X_train_normalized, a )), a\n",
    "    assert np.all(np.isclose( X_test_normalized, b )), b\n",
    "    print('Test passed', '\\U0001F44D')    \n",
    "if __name__==\"__main__\":\n",
    "    test_normalizeX()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AJ_OSEoQLEuc"
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    '''\n",
    "    Input:\n",
    "        x: numpy array of any shape\n",
    "    Output:\n",
    "        y: numpy array of same shape as x\n",
    "    '''\n",
    "    y = 1/(1+np.exp(-x))\n",
    "    ### WRITE YOUR CODE HERE - 1 MARKS\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed üëç\n"
     ]
    }
   ],
   "source": [
    "def test_sigmoid():\n",
    "    x = np.array([np.log(4),np.log(0.25),0])\n",
    "    y = sigmoid(x)\n",
    "    assert np.all(np.isclose( y, np.array([0.8, 0.2, 0.5]) )), y\n",
    "    print('Test passed', '\\U0001F44D')    \n",
    "if __name__==\"__main__\":\n",
    "    test_sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    '''\n",
    "    Input:\n",
    "        x: numpy array of any shape\n",
    "    Output:\n",
    "        y: numpy array of same shape as x\n",
    "    '''\n",
    "    y = np.exp(x)/np.sum(np.exp(x))\n",
    "    ### WRITE YOUR CODE HERE - 1 MARKS\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed üëç\n"
     ]
    }
   ],
   "source": [
    "def test_softmax():\n",
    "    x = np.array([np.log(2),np.log(7),0])\n",
    "    y = softmax(x)\n",
    "    assert np.all(np.isclose( y, np.array([0.2, 0.7, 0.1]) )), y\n",
    "    print('Test passed', '\\U0001F44D')    \n",
    "if __name__==\"__main__\":\n",
    "    test_softmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Iwi4QwxlOAOR"
   },
   "outputs": [],
   "source": [
    "def sigmoid_derivative(x):\n",
    "    '''\n",
    "    Input:\n",
    "        x: numpy array of any shape; it is sigmoid layer's output\n",
    "    Output:\n",
    "        y: numpy array of same shape as x; it is the derivative of sigmoid\n",
    "    '''\n",
    "\n",
    "    ### WRITE YOUR CODE HERE - 1 MARKS\n",
    "    y = x*(1-x)\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, ni, nh, no):\n",
    "        '''   \n",
    "        Input:\n",
    "            ni: int, size of input layer\n",
    "            nh: int, size of hidden layer\n",
    "            no: int, size of output layer\n",
    "        Action:\n",
    "            Creates instance variables\n",
    "        NOTE: We do not use bias explicitly here. Input x can have the first element 1 to have a bias term.\n",
    "        '''\n",
    "        self.ni = ni\n",
    "        self.nh = nh\n",
    "        self.no = no\n",
    "        self.weights1 = []\n",
    "        self.weights2 = []\n",
    "        return\n",
    "    \n",
    "    def init_weights(self):\n",
    "        '''\n",
    "        Action:\n",
    "            Randomly initialize weights1 and weights2 with proper size random np arrays\n",
    "        '''\n",
    "\n",
    "        ### WRITE YOUR CODE HERE - 2 MARKS\n",
    "        self.weights1 = np.random.randn(self.nh,self.ni+1)\n",
    "        self.weights2 = np.random.randn(self.no,self.nh+1)\n",
    "\n",
    "    \n",
    "    def predict(self, x):\n",
    "        x = np.insert(x,0,1,axis=0) # inserts a row of 1s. This is for the bias\n",
    "        h1 = self.weights1.dot(x)\n",
    "        v1 = sigmoid(h1)\n",
    "        v1 = np.insert(v1,0,1,axis=0) # inserts a row of 1s. This is for the bias\n",
    "        h2 = self.weights2.dot(v1)\n",
    "        v2 = softmax(h2)\n",
    "        return v2\n",
    "\n",
    "    def backprop(self,x1,y1,eta):\n",
    "        '''\n",
    "        # application of the chain rule to find derivative of the categorical cross entropy loss function with respect to weights2 and weights1\n",
    "        Input:\n",
    "            x: numpy array of shape (ni,1)\n",
    "            y: numpy array of shape (no,1)\n",
    "            eta: learning rate\n",
    "        Action:\n",
    "            # Finding the derivatives\n",
    "            del_weights2: np array that stores the derivative of the loss function with respect to weights2\n",
    "            del_weights1: np array that stores the derivative of the loss function with respect to weights1\n",
    "\n",
    "            # Update the weights with the derivative of the categorical cross entropy loss function\n",
    "              weights1 += eta*del_weights1\n",
    "              weights2 += eta*del_weights2\n",
    "        ''' \n",
    "\n",
    "        ### WRITE YOUR CODE HERE - 5 MARKS\n",
    "        x = np.zeros((len(x1),1))\n",
    "        y = np.zeros((len(y1),1))\n",
    "        for i in range(len(x1)):\n",
    "            x[i][0]=x1[i]\n",
    "        for i in range(len(y1)):\n",
    "            y[i][0]=y1[i]\n",
    "        x = np.insert(x,0,1,axis=0)# inserts a row of 1s. This is for the bias\n",
    "        h1 = self.weights1.dot(x)\n",
    "        v1 = sigmoid(h1)\n",
    "        v1 = np.insert(v1,0,1,axis=0) # inserts a row of 1s. This is for the bias\n",
    "        h2 = self.weights2.dot(v1)\n",
    "        v2 = softmax(h2)\n",
    "        del_weights2 = - (y-v2).dot(v1.T)\n",
    "        w2 = self.weights2\n",
    "        w2 = w2[:,1:]\n",
    "        del_weights1 = (((w2.T).dot(- y + v2))*sigmoid_derivative(v1[1:,:])).dot(x.T)\n",
    "        self.weights2 -= eta*del_weights2\n",
    "        self.weights1 -= eta*del_weights1\n",
    "\n",
    "\n",
    "    def fit(self, X, t, eta, epochs):\n",
    "        '''\n",
    "        input:\n",
    "            X: training input data \n",
    "            t: training targets\n",
    "            eta: learning rate\n",
    "            epochs: number of epochs\n",
    "        Action:\n",
    "            train the weights\n",
    "        '''\n",
    "\n",
    "        ### WRITE YOUR CODE HERE - 5 MARKS\n",
    "        E1,e1 = [],[]\n",
    "        decay = (eta*(1.0))/epochs\n",
    "        for i in range(epochs):\n",
    "            E=0\n",
    "            for j in range(X.shape[0]):\n",
    "                x = np.zeros((len(X[j]),1))\n",
    "                for k in range(len(X[j])):\n",
    "                    x[k][0]=X[j][k]\n",
    "                y = self.predict(x)\n",
    "                self.backprop(x,t[j].T,eta)\n",
    "                if(i%20==0):\n",
    "                    E += -t[j].dot(np.log10(y))\n",
    "            #eta *= (1. / (1. + decay * i))\n",
    "            if(i%20==0):\n",
    "                print(E)\n",
    "                E1.append(E)\n",
    "                e1.append(i)\n",
    "        return E1,e1\n",
    "\n",
    "        \n",
    "    def predict_label(self,x):    \n",
    "        '''\n",
    "        Output:\n",
    "            y: np array of index\n",
    "        '''\n",
    "\n",
    "        ### WRITE YOUR CODE HERE - 1 MARKS\n",
    "        y = np.zeros((x.shape[0],1))\n",
    "        for i in range(x.shape[0]):\n",
    "            y[i][0]=np.argmax(self.predict(x[i].T))\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "fmR8F2JIFwqm",
    "outputId": "fa868689-92c8-4a43-882f-3321cde1a301"
   },
   "outputs": [],
   "source": [
    "### Lastly, report the accuracy of your model and print the Confusion Matrix\n",
    "#printing the confusion matrix\n",
    "def getCM(y,t):\n",
    "    '''\n",
    "    Inputs:\n",
    "        y: estimated labels np array (Nsample,1)\n",
    "        t: targets np array (Nsamples,1)\n",
    "    Outputs:\n",
    "        CM : np array of confusion matrix\n",
    "    '''\n",
    "    ### WRITE YOUR CODE HERE - 3 MARKS\n",
    "    CM = np.zeros((t.shape[1],t.shape[1]))\n",
    "    for i in range(y.shape[0]):\n",
    "        j = np.argmax(t[i])\n",
    "        CM[j][int(y[i])]+=1\n",
    "\n",
    "    return CM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiments\n",
    "Use the above functions to carry out the experiment:\n",
    "- load iris data and prepare it for NN\n",
    "- split randomly into 20% test data\n",
    "- create a NN with 1 hidden layer\n",
    "- train the network with training data\n",
    "- Plot loss w.r.t. number of epochs\n",
    "- Print confusion matrix on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "hewsBv12weZ2",
    "outputId": "52407420-e7e5-4ca6-952b-6448ffe4b101",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(150,)\n",
      "[68.2473479]\n",
      "[36.74932271]\n",
      "[30.78526514]\n",
      "[27.7285605]\n",
      "[25.63272431]\n",
      "[24.04042308]\n",
      "[22.74502486]\n",
      "[21.63663388]\n",
      "[20.65382681]\n",
      "[19.76130211]\n",
      "[18.93825159]\n",
      "[18.17195324]\n",
      "[17.45414863]\n",
      "[16.77901013]\n",
      "[16.14204491]\n",
      "[15.53954327]\n",
      "[14.96832483]\n",
      "[14.42563196]\n",
      "[13.90908416]\n",
      "[13.41664997]\n",
      "[12.94661801]\n",
      "[12.49756205]\n",
      "[12.06830115]\n",
      "[11.65785746]\n",
      "[11.26541449]\n",
      "[10.89027793]\n",
      "[10.53184077]\n",
      "[10.18955334]\n",
      "[9.86289904]\n",
      "[9.55137564]\n",
      "[9.25448202]\n",
      "[8.97170983]\n",
      "[8.70253926]\n",
      "[8.44643828]\n",
      "[8.2028642]\n",
      "[7.97126706]\n",
      "[7.75109378]\n",
      "[7.54179286]\n",
      "[7.34281879]\n",
      "[7.15363623]\n",
      "[6.97372355]\n",
      "[6.80257572]\n",
      "[6.63970659]\n",
      "[6.48465047]\n",
      "[6.33696319]\n",
      "[6.19622268]\n",
      "[6.0620291]\n",
      "[5.93400468]\n",
      "[5.81179327]\n",
      "[5.69505975]\n",
      "[5.58348918]\n",
      "[5.476786]\n",
      "[5.37467306]\n",
      "[5.27689068]\n",
      "[5.18319562]\n",
      "[5.09336019]\n",
      "[5.00717124]\n",
      "[4.92442927]\n",
      "[4.84494752]\n",
      "[4.76855119]\n",
      "[4.69507656]\n",
      "[4.62437032]\n",
      "[4.55628881]\n",
      "[4.49069736]\n",
      "[4.4274697]\n",
      "[4.36648736]\n",
      "[4.30763914]\n",
      "[4.25082058]\n",
      "[4.19593355]\n",
      "[4.14288577]\n",
      "[4.09159041]\n",
      "[4.04196577]\n",
      "[3.99393487]\n",
      "[3.94742517]\n",
      "[3.90236824]\n",
      "[3.85869953]\n",
      "[3.8163581]\n",
      "[3.77528635]\n",
      "[3.73542985]\n",
      "[3.6967371]\n",
      "[3.65915936]\n",
      "[3.62265047]\n",
      "[3.58716672]\n",
      "[3.55266661]\n",
      "[3.51911083]\n",
      "[3.48646203]\n",
      "[3.45468474]\n",
      "[3.42374528]\n",
      "[3.39361159]\n",
      "[3.36425322]\n",
      "[3.33564114]\n",
      "[3.30774775]\n",
      "[3.28054672]\n",
      "[3.25401298]\n",
      "[3.2281226]\n",
      "[3.20285276]\n",
      "[3.17818168]\n",
      "[3.15408855]\n",
      "[3.13055349]\n",
      "[3.1075575]\n",
      "[[ 7.  0.  0.]\n",
      " [ 0.  6.  2.]\n",
      " [ 0.  1. 14.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def experiment():\n",
    "\n",
    "    ### WRITE YOUR CODE HERE - 10 MARKS\n",
    "    nh = 4\n",
    "    eta = 0.001\n",
    "    epochs = 2000\n",
    "    X,t1 = loadIrisData()\n",
    "    t1 = one_hot_encoding(t1,3)\n",
    "    X_train, t_train, X_test, t_test = splitData(X,t1,0.2)\n",
    "    X_train,X_test = normalizeX(X_train,X_test)\n",
    "    NN = NeuralNetwork(X_train.shape[1],nh,3)\n",
    "    NN.init_weights()\n",
    "    loss,eps = NN.fit(X_train,t_train,eta,epochs)\n",
    "    y = NN.predict_label(X_test)\n",
    "    CM = getCM(y,t_test)\n",
    "    print(CM)\n",
    "    plt.plot(eps,loss,'ro-')\n",
    "    \n",
    "if __name__==\"__main__\":\n",
    "    experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "BP_Iris.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
